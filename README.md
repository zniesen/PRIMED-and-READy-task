# PRIMED and READy: A Multimodal Semantic Priming Task
This repository contains the Inquisit .iqx script for a cross-modal priming task designed to investigate semantic priming effects across auditory and visual modalities. 
The task presents an auditory prime followed by a visual target word, and participants judge whether the two words are semantically related.

Table of Contents
---
   * [About the Project](#about-the-project)
   * [Task](#task)
   * [Modifications and Authorship](#modifications)
   * [License](#license)

## About the Project
### Use Case
Originally developed for use in a neuroscience research context with fNIRS data collection. 
This task was used as one of several behavioral tasks in a larger cognitive and brain imaging study.

### Languages Used
- Inquisit

## Task
### Modality
Auditory prime → Visual target
### Trial Structure
  1. Auditory word is played
  2. Visual word is displayed
  3. Participant responds:
      - A key = Related
      - L key = Unrelated
### Trials
24 total (randomized)
### Response types
Accuracy and latency are recorded
### Estimated duration
~5 minutes
### Output
Standard Inquisit .iqdat files
### Requirements
Inquisit 6
Headphones (recommended)

## Modifications
- Based on the original script by Katja Borchert, Ph.D. for Millisecond Software
- This version was adapted by Zoe Niesen in September 2024 for the NEU-4800 Neuroimaging course at Belmont University (09/2024)
- Original script: [Millisecond Library – Subliminal Priming](https://www.millisecond.com/download/library/subliminalpriming)

## License
This adaptation is for academic use only. The base script is © Millisecond Software and distributed under their licensing terms.
